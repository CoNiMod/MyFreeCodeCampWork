# -*- coding: utf-8 -*-
"""fcc_predict_health_costs_with_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/freeCodeCamp/boilerplate-linear-regression-health-costs-calculator/blob/master/fcc_predict_health_costs_with_regression.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries. You may or may not use all of these.
# !pip install -q git+https://github.com/tensorflow/docs
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

try:
    # %tensorflow_version only exists in Colab.
    # %tensorflow_version 2.x
    pass
except Exception:
    pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

# import tensorflow_docs as tfdocs
# import tensorflow_docs.plots
# import tensorflow_docs.modeling

# Import data
# !wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv
dataset = pd.read_csv('insurance.csv')
print("数据集形状:", dataset.shape)
print("数据集前5行:")
print(dataset.head())
print("\n数据集信息:")
print(dataset.info())

# 数据预处理：将分类数据转换为数字
# 检查分类列
categorical_columns = ['sex', 'smoker', 'region']
numerical_columns = ['age', 'bmi', 'children']

print(f"\n分类列: {categorical_columns}")
print(f"数值列: {numerical_columns}")

# 将分类数据转换为数字
for col in categorical_columns:
    dataset[col] = pd.Categorical(dataset[col]).codes

print("\n转换后的数据集前5行:")
print(dataset.head())

# 划分训练集和测试集 (80% 训练, 20% 测试)
from sklearn.model_selection import train_test_split

# 分离特征和标签
features = dataset.drop('expenses', axis=1)
labels = dataset['expenses']

# 划分数据集
train_dataset, test_dataset, train_labels, test_labels = train_test_split(
    features, labels, test_size=0.2, random_state=42
)

print(f"\n训练集大小: {len(train_dataset)}")
print(f"测试集大小: {len(test_dataset)}")
print(f"训练标签大小: {len(train_labels)}")
print(f"测试标签大小: {len(test_labels)}")

# 数据标准化
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
train_dataset_scaled = scaler.fit_transform(train_dataset)
test_dataset_scaled = scaler.transform(test_dataset)

# 转换为DataFrame以保持列名
train_dataset_scaled = pd.DataFrame(train_dataset_scaled, columns=train_dataset.columns)
test_dataset_scaled = pd.DataFrame(test_dataset_scaled, columns=test_dataset.columns)

print("\n标准化后的训练集统计:")
print(train_dataset_scaled.describe())

# 创建线性回归模型
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dropout(0.2),
    layers.Dense(32, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(16, activation='relu'),
    layers.Dense(1)
])

# 编译模型
model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae', 'mse']
)

print("\n模型结构:")
model.summary()

# 训练模型
print("\n开始训练模型...")
history = model.fit(
    train_dataset_scaled, 
    train_labels,
    epochs=100,
    validation_split=0.2,
    verbose=1
)

# 绘制训练历史
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['mae'], label='训练 MAE')
plt.plot(history.history['val_mae'], label='验证 MAE')
plt.title('模型训练历史 - MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='训练损失')
plt.plot(history.history['val_loss'], label='验证损失')
plt.title('模型训练历史 - 损失')
plt.xlabel('Epoch')
plt.ylabel('损失')
plt.legend()

plt.tight_layout()
plt.show()

# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.
# Test model by checking how well the model generalizes using the test set.
loss, mae, mse = model.evaluate(test_dataset_scaled, test_labels, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} expenses".format(mae))

if mae < 3500:
    print("You passed the challenge. Great job!")
else:
    print("The Mean Abs Error must be less than 3500. Keep trying.")

# Plot predictions.
test_predictions = model.predict(test_dataset_scaled).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_labels, test_predictions)
plt.xlabel('True values (expenses)')
plt.ylabel('Predictions (expenses)')
lims = [0, 50000]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims,lims)
plt.title('预测值 vs 真实值')
plt.show()

# 额外分析：特征重要性
feature_importance = pd.DataFrame({
    'feature': train_dataset.columns,
    'importance': np.abs(model.layers[0].get_weights()[0].mean(axis=1))
})
feature_importance = feature_importance.sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.bar(feature_importance['feature'], feature_importance['importance'])
plt.title('特征重要性分析')
plt.xlabel('特征')
plt.ylabel('重要性')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("\n特征重要性排序:")
print(feature_importance)